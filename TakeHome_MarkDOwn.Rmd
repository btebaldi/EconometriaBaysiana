---
title: "Econometria Baysiana - Take Home Exam"
Auhtor: "B"
date: "13/02/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

Consider the regression model
$y_i = x_i'\beta + \epsilon_i0$
$\epsilon_i | \lambda_i ,\sigma^2 \sim N(0, \lambda_i\sigma^2)$
where $x_i = (1, x_{i1}, \dots, x_{iq})'$ is a p-dimensional vector of regressors (constant plus q attributes or
characteristics) and the following hierarchical prior for the scale-mixing variables $\lambda_i$:
$\lambda_1, \dots, \lambda_n$ iid Exponential(1/2):

Recall that
\[	f(\lambda) = \lambda e^{{-\lambda x}}\]

### PART A)

$$\begin{aligned}
p\left(\epsilon_{i} | \sigma^{2}\right) &=\int_{0}^{\infty} p\left(\epsilon_{i} | \lambda_{i}, \sigma^{2}\right) p\left(\lambda_{i}\right) d \lambda_{i} \\
&=\int_{0}^{\infty}\left(2 \pi \lambda_{i} \sigma^{2}\right)^{-1 / 2} \exp \left[-\epsilon_{i}^{2} /\left(2 \lambda_{i} \sigma^{2}\right)\right](1 / 2) \exp \left(-\lambda_{i} / 2\right) d \lambda_{i} \\
&=(1 / 2)\left(2 \pi \sigma^{2}\right)^{-1 / 2} \int_{0}^{\infty} \lambda_{i}^{-1 / 2} \exp \left[-(1 / 2)\left(\lambda_{i}+\left[\epsilon_{i} / \sigma\right]^{2} \lambda_{i}^{-1}\right)\right] d \lambda_{i}
\end{aligned}$$

Now, make a change of variable and let $\psi_i = \lambda_i^{1/2}$. We can then express this integral as

$$
p\left(\epsilon_{i} | \sigma^{2}\right)=\left(2 \pi \sigma^{2}\right)^{-1 / 2} \int_{0}^{\infty} \exp \left(-[1 / 2]\left(\psi_{i}^{2}+\left[\epsilon_{i} / \sigma\right]^{2} \psi_{i}^{-2}\right)\right) d \psi_{i}
$$

The integral in above can be evaluated analytically. Using the following result from Andrews and Mallows (1974) 
$$
\int_{0}^{\infty} \exp \left\{-0.5\left(a^{2} u^{2}+b^{2} u^{-2}\right)\right\} d u=\left(\frac{\pi}{2 a^{2}}\right)^{1/2} \exp \{-|a b|\}
$$
Then $a=1$, $b=\epsilon_i/\sigma$, and $u = \psi_i$

$$
p\left(\epsilon_{i} | \sigma^{2}\right)=\left(2 \pi \sigma^{2}\right)^{-1 / 2} \left(\frac{\pi}{2}\right)^{1/2} \exp\{-|\epsilon_i/\sigma|\} =\frac{1}{2\sigma} \exp\left\{-\frac{|\epsilon_i|}{\sigma}\right\}
$$

###  PART B)

Let $y = (y_1, \dots, y_n)'$ and $X = (x_1, \dots, x_n)'$. Where we have the the following independent priors for $\beta \sim N(\beta_0, V_0)$ and $\sigma^2 \sim IG\left(\frac{\nu_0}{2}, \frac{\nu_0\sigma_0^2}{2}\right)$.

where $\mathcal{D} = \{y;X\}$ is the data;

Also let
$$
\Lambda  = \begin{bmatrix}\lambda_1 & 0 & \dots & 0 \\ 0 & \lambda_2 & \dots & 0 \\ 0 & \vdots & \ddots & 0 \\ 0 & 0 & 0 & \lambda_n \end{bmatrix}
$$
If $\beta \sim N(\beta_0, V_0)$, then
$$
\begin{align}
p\left(y | X, \beta, \sigma^{2}, \{\lambda_i\}\right) 
&\propto \exp \left\{-\frac{1}{2 \sigma^{2}} \sum_{i=1}^{n} \hat\epsilon_i \right\} \\
&\propto \exp \left\{-\frac{1}{2 \sigma^{2}}\left[\boldsymbol{y}^{T} \boldsymbol{y}-2 \boldsymbol{\beta}^{T} \mathbf{X}^{T}\Lambda^{-1} \boldsymbol{y}+\boldsymbol{\beta}^{T} \mathbf{X}^{T}\Lambda^{-1} \mathbf{X} \boldsymbol{\beta}\right]\right\} \\
p\left(\boldsymbol{\beta} | \{\lambda_i\}, \sigma^2, \mathcal{D}\right) &\propto p\left(\boldsymbol{y} | \mathbf{X}, \boldsymbol{\beta}, \sigma^{2}\right) \times p(\boldsymbol{\beta}) \\
&\propto \exp \left\{-\frac{1}{2\sigma^2}\left(-2 \boldsymbol{\beta}^{T} \mathbf{X}^{T}\Lambda^{-1} \boldsymbol{y} +\boldsymbol{\beta}^{T} \mathbf{X}^{T}\Lambda^{-1} \mathbf{X} \boldsymbol{\beta} \right)-\frac{1}{2}\left(-2 \boldsymbol{\beta}^{T} V_{0}^{-1} \boldsymbol{\beta}_{0}+\boldsymbol{\beta}^{T} V_{0}^{-1} \boldsymbol{\beta}\right)\right\} \\
&\propto 
\exp \left\{-\frac{1}{2\sigma^2}\left(-2 \boldsymbol{\beta}^{T} (\mathbf{X}^{T}\Lambda^{-1} \boldsymbol{y} +V_{0}^{-1} \boldsymbol{\beta}_{0})+\boldsymbol{\beta}^{T} (\mathbf{X}^{T}\Lambda^{-1} \mathbf{X} +V_{0}^{-1} ) \boldsymbol{\beta} \right)
\right\}
\end{align}
$$
we recognize this as being proportional to a multivariate normal density, with
$$
\begin{align}
\beta | \{\lambda_i\}, \sigma^2, \mathcal{D} \sim N(\beta_1, V_1) \\
\beta_{1}=V_{1}\left(X^{\prime} \Lambda^{-1} y+V_{0}^{-1} \beta_{0}\right) \qquad V_{1}=\left(X^{\prime} \Lambda^{-1} X / \sigma^{2}+V_{0}^{-1}\right)^{-1}
\end{align}
$$

$$
V_{1}=\left(X^{\prime} \Lambda^{-1} X / \sigma^{2}+V_{0}^{-1}\right)^{-1} \qquad \beta_{1}=V_{1}\left(X^{\prime} \Lambda^{-1} y+V_{0}^{-1} \beta_{0}\right)
$$

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
